{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c646f-ff78-4179-a1b9-85d775841565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the JSON data\n",
    "with open('netstats-315-326.json') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5dcc7f-58f5-4306-b7b1-c73de42840ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daec9a-9148-40d0-ad2a-a1812a11d375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320a8cc-bb20-468d-b8b7-bb1cced26060",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b334aa-8afd-4a05-96a5-f92d35023d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_blanks(df, srl_num, range_df, date_variable):\n",
    "    \"\"\"\n",
    "    Fills missing observations for time series data.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data to be processed.\n",
    "    - srl_num: The column name in df that contains the series identifiers.\n",
    "    - range_df: DataFrame containing the complete range of dates.\n",
    "    - date_variable: The column name in both df and range_df that contains the date information.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with missing observations filled.\n",
    "    \"\"\"\n",
    "    filled_dfs = []  # List to hold the filled DataFrames for each unique series identifier\n",
    "\n",
    "    for comb in df[srl_num].unique():\n",
    "        #print('Processing series:', comb)\n",
    "        temp = df[df[srl_num] == comb].copy()\n",
    "        temp2 = range_df.merge(temp, how='left', on=date_variable)\n",
    "        # Forward fill and then back fill to cover all missing values\n",
    "        temp2.fillna(method='ffill', inplace=True)\n",
    "        temp2.fillna(method='bfill', inplace=True)\n",
    "        filled_dfs.append(temp2)\n",
    "\n",
    "    # Concatenate all filled DataFrames\n",
    "    filled_df = pd.concat(filled_dfs, ignore_index=True)\n",
    "\n",
    "    return filled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb1d23-d46a-4939-a825-fe8a086def4f",
   "metadata": {},
   "source": [
    "### Dataset clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc221e-972a-461f-ae67-4d7f68e68572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove \".os.net.ibm.com\" from all host names\n",
    "df['host'] = df['host'].str.replace('.os.net.ibm.com', '', regex=False)\n",
    "\n",
    "# Identify columns where all values are zero\n",
    "zero_only_columns = [col for col in df.columns if (df[col] == 0).all()]\n",
    "packets_columns = [col for col in df.columns if 'packets' in col]\n",
    "dropped_columns = [col for col in df.columns if'dropped' in col]\n",
    "single_value_columns = list(df.columns[df.nunique() == 1])\n",
    "\n",
    "# combine\n",
    "columns_to_drop = list(set(zero_only_columns + packets_columns + dropped_columns + single_value_columns))\n",
    "\n",
    "# Drop these columns from the DataFrame\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Ensure 'ts' column is in datetime format\n",
    "df_cleaned['ts'] = pd.to_datetime(df_cleaned['ts'])\n",
    "\n",
    "df_cleaned['ts'] = df_cleaned['ts'].dt.floor('T') \n",
    "\n",
    "# create unique column - serialize\n",
    "df_cleaned['site_host'] = df_cleaned['site'] + \"_\" + df_cleaned['host']\n",
    "\n",
    "# sort\n",
    "df_cleaned.sort_values(by=['site_host','ts'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd50038-52cc-47b1-b4af-eb2cf12dd3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990ee39-6283-4c3d-a51e-ed49b1318652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc5c6d-e968-455b-ad7f-2e267f0a9af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_range = df_cleaned.ts.drop_duplicates()\n",
    "date_range = pd.DataFrame(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77e1ac-7c48-4b5a-867f-a3f86b3b8241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ready = fill_blanks(df_cleaned,'site_host',date_range,'ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28137cbc-1f53-471f-976c-93421a7a8e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the first few rows to understand the data structure\n",
    "df_ready.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58445c-3da0-4661-a211-699f47c20546",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af8b752-c5ab-49b8-8e0c-4e839d9c91bf",
   "metadata": {},
   "source": [
    "### Get number of unique hosts / interface / and combination of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557c549-2458-473d-8b22-db8026d976b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of unique hosts: {len(df_ready.site.unique())}\")\n",
    "print(f\"Number of unique interfaces: {len(df_ready.host.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41817397-1a3e-4ea1-8e90-c472b449a344",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Check for equal # of observations** <br>\n",
    "accross all site /host combinatipons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c80fc4-4ea6-41f0-9e37-c51022938f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count of records per site/host comb\n",
    "counts_per_site_host = df_ready.groupby(['site', 'host']).size().reset_index(name='count')\n",
    "\n",
    "# looks for a single \n",
    "for cnt in counts_per_site_host['count'].unique():\n",
    "    print(counts_per_site_host[counts_per_site_host['count'] == cnt].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552bf84-bed2-4b78-9adf-369f8509837a",
   "metadata": {},
   "source": [
    "After fill_blanks function all sites-host, combination have same number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78592ad-42e7-41e6-bd03-5b49ad4ba1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display basic information about the DataFrame\n",
    "df_ready.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca562dd-ed2e-45db-8cf7-bbca5257a471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ready.to_csv('netstats_4_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395f1f2-715a-4973-be0c-6fca6d599ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
